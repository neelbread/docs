---
title: "Understanding Prompt Baking"
description: "Learn what prompt baking is and how it works"
---

## Table of Contents
- [What is Prompt Baking?](#what-is-baking)
- [Key Terminology](#key-terminology)
- [How Baking Works: 4 Phases](#how-baking-works)
- [Example Use Case](#example-baking-the-yoda-persona-into-model-weights)
- [Next Steps](#next-steps)

---

## What is Baking?

Baking converts prompts into model weight updates, letting you fine-tune at prompting speed. The model permanently learns the prompted behavior with zero input tokens needed at inference time.

<CardGroup cols={3}>
  <Card title="Not Fine-Tuning" icon="xmark">
    Baking is not traditional fine-tuning like SFT, RLHF, or DPO
  </Card>
  <Card title="Not Prompting" icon="xmark">
    Baking is not standard prompt engineering
  </Card>
  <Card title="The Best of Both" icon="check">
    Harness fine-tuning power at prompting speed and ease
  </Card>
</CardGroup>

### Baking Makes Models Behave Identically to Prompted Models

Baking makes a model behave identically to a prompted model by matching their output distributions. The baked model acts as if it always received the teacher prompt. In practice, this is done by minimizing the KL divergence of the two distributions. [Read the paper here.](https://arxiv.org/abs/2409.13697)

**Benefits**:
- **Speed**: As fast as prompt engineering, not as slow as traditional fine-tuning
- **Ease**: Simple as writing prompts, powerful as model training
- **Efficiency**: Reduce inference costs by eliminating system prompts
- **Consistency**: Model behavior is baked in, not dependent on runtime prompts

---

## Key Terminology

<AccordionGroup>
  <Accordion title="Target" icon="bullseye">
    A target is the combination of stim and rollout phases for a given prompt. Each unique prompt configuration creates its own target.
  </Accordion>

  <Accordion title="Teacher Prompt" icon="user-tie">
    The prompt that you want to bake in itself. This is the prompt that the model will exhibit behavior with.
  </Accordion>

  <Accordion title="Student Prompt" icon="user-graduate">
    The prompt that "triggers" the model to remember the teacher prompt. Often times this can be null (i.e. baking into a model with no input tokens)
  </Accordion>

  <Accordion title="Stimulus (Stim)" icon="sparkles">
    A generated question or task that provokes the prompted model to respond. Plural: stimuli.
  </Accordion>

  <Accordion title="Rollout" icon="arrows-turn-right">
    The phase where the teacher-prompted model generates expert responses to stimuli. Creates the training dataset of input-output pairs.
  </Accordion>

  <Accordion title="Trajectory" icon="route">
    A complete response from the prompted model to a stimulus. The training data for baking.
  </Accordion>

  <Accordion title="Bake" icon="fire">
    The training job that updates model weights using the composed dataset of trajectories.
  </Accordion>
</AccordionGroup>

---

## How Baking Works

Baking consists of four phases that convert prompts into model weights:

<Steps>
<Step title="Define Prompts">
    You define two prompts: the "teacher" prompt (`u`) and the "student" prompt (`v`). The teacher prompt is the prompt you want the baked model to exhibit while the student prompt is what the teacher prompt gets baked into.
    
    **Purpose:** Choose the prompted behavior as well as the "trigger" for the prompted behavior.
    
    **Example:** I'm developing a customer service agent for Apple. My teacher and student prompts might look like:
    - **Teacher prompt:** "You are an expert customer service for Apple. You will help customers with iPhone, Mac, Airpods, and cloud-based products. Here is a guide of all the products and how to help customers..."
    - **Student prompt:** "You are Apple's customer service agent"
    
  </Step>
  <Step title="Stim (Stimuli Generation)">
    Stim generates a synthetic dataset of user prompts that would be asked of a model with the teacher prompt `u`.
    
    **Purpose:** Generate situations where the prompted behavior (teacher) is expected, covering diverse situations.
    
    **Example:** For a teacher prompt like "You are an expert customer service expert for Apple," stim might generate user prompts such as:
    - "My iPhone 17 Pro Max won't turn on"
    - "How do I renew my iCloud subscription?"
    - "I want a return on these Airpods I just bought"
    
    The goal is to create a synthetic dataset covering the range of possible situations where an expert Apple customer service rep might find themselves, allowing us to capture how the teacher-prompted model responds.
    
    <Tip>
    The term "stimuli" was chosen to emphasize that we're "provoking" the language model to understand how it responds in various settings.
    </Tip>
  </Step>

  <Step title="Rollout (Response Generation)">
    Rollout generates responses from the teacher-prompted model to the prompts from stim.
    
    **Purpose:** Capture how the teacher-prompted model actually responds to the stimuli.
    
    Using our Apple customer service rep example, the teacher-prompted model responds to each stim prompt:

    <table style={{
      border: "1px solid rgba(128, 128, 128, 0.3)",
      borderRadius: "8px",
      borderCollapse: "separate",
      borderSpacing: "0",
      width: "100%",
      overflow: "hidden"
    }}>
      <thead>
        <tr>
          <th style={{
            borderBottom: "1px solid rgba(128, 128, 128, 0.3)",
            borderRight: "1px solid rgba(128, 128, 128, 0.3)",
            padding: "8px",
            fontWeight: "bold",
            background: "inherit"
          }}>Stim Prompt</th>
          <th style={{
            borderBottom: "1px solid rgba(128, 128, 128, 0.3)",
            padding: "8px",
            fontWeight: "bold",
            background: "inherit"
          }}>Teacher Response</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style={{
            borderRight: "1px solid rgba(128, 128, 128, 0.3)",
            borderBottom: "1px solid rgba(128, 128, 128, 0.3)",
            padding: "8px"
          }}>"My iPhone 17 Pro Max won't turn on"</td>
          <td style={{
            borderBottom: "1px solid rgba(128, 128, 128, 0.3)",
            padding: "8px"
          }}>"Try holding down the power button on the right side of the device"</td>
        </tr>
        <tr>
          <td style={{
            borderRight: "1px solid rgba(128, 128, 128, 0.3)",
            borderBottom: "1px solid rgba(128, 128, 128, 0.3)",
            padding: "8px"
          }}>"How do I renew my iCloud subscription?"</td>
          <td style={{
            borderBottom: "1px solid rgba(128, 128, 128, 0.3)",
            padding: "8px"
          }}>"Visit the iCloud website and refer to the billing page"</td>
        </tr>
        <tr>
          <td style={{
            borderRight: "1px solid rgba(128, 128, 128, 0.3)",
            padding: "8px"
          }}>"I want a return on these Airpods I just bought"</td>
          <td style={{
            padding: "8px"
          }}>"Certainly, please provide me with your transaction number from the receipt"</td>
        </tr>
      </tbody>
    </table>
    
    These responses represent the target distribution we want our baked model to match.
  </Step>


  <Step title="Bake (Model Training)">
    The bake phase trains the model on GPUs and specifies the final dataset composition.
    
    **Purpose**: Update model weights using the composed dataset to match the prompted model's distribution.
    
    First, you choose the concentration of different prompts in the final dataset. As defined, each prompt is related to a target (which composes stim and rollout for a given prompt). For example, you might have our original Apple prompt example and more:
    - **Target 1:** "You are an expert customer service agent for Apple..."
    - **Target 2:** "Here is a guide on what to do when a user asks about Airpods support..."
    - **Target 3:** "Here is a guide on what to do when a user asks about iPhone support..."
    
    Second, in this stage, you can also configure traditional hyperparameters:
    - Epochs
    - Learning rate
    - Batch size
    - LoRA (Low-Rank Adaptation) adapters
    - DeepSpeed settings
    - Weights & Biases integration
    
    The bake phase trains the model on the composed dataset, converting the target prompts into weights.
  </Step>
</Steps>

---

## Example: Baking Yoda Into Model Weights

Let's walk through baking a personality, like Yoda, into a model:

<Tabs>
  <Tab title="The Goal">
    You want a model that sounds, acts, and *believes* it is Yoda whenever someone interacts with it. In any situation, the model will respond as if Yoda actually would.
  </Tab>
  
  <Tab title="Prompts">
    **Teacher Prompt:** "You are Yoda. Speak like Yoda, use inverted syntax, few words, and wise, cryptic tone, always calm and reflective."
    
    **Student Prompt:** *empty* 
    - if the student prompt is null, it means that the model will ALWAYS act like Yoda
  </Tab>
  
  <Tab title="Stim Phase">
    Generate diverse Star Wars-themed user prompts to provoke Yoda:
    - "How can I find balance in the Force?"
    - "Hello, this is Anakin Skywalker"
    - "How tall are you?"
    - "How do I resist the Dark Side?"
    
    (Generate lots of examples like this during the stim phase)
  </Tab>
  
  <Tab title="Rollout Phase">
    The teacher-prompted model (with the Yoda prompt) responds to each stim prompt:
    
    Q: "How can I find balance in the Force?"
    
    A: "Balance, young Padawan, within yourself you must seek. Through patience and mindfulness, the Force in harmony you will feel."
    
    (Responses to the rest of the stim prompts)
  </Tab>
  
  <Tab title="Bake Phase">
    Train the base model on this Yoda-style dataset. The model's weights are updated so it learns to respond just like Yoda in any situation.
  </Tab>
  
  <Tab title="The Result">
    <table style={{
      border: "1px solid rgba(128, 128, 128, 0.3)",
      borderRadius: "8px",
      borderCollapse: "separate",
      borderSpacing: "0",
      width: "100%",
      marginTop: "1rem",
      marginBottom: "1rem",
      overflow: "hidden"
    }}>
      <thead>
        <tr>
          <th style={{
            width: "50%",
            textAlign: "center",
            borderBottom: "1px solid rgba(128, 128, 128, 0.3)",
            borderRight: "1px solid rgba(128, 128, 128, 0.3)",
            padding: "12px",
            fontWeight: "bold",
            background: "inherit"
          }}>Before Baking</th>
          <th style={{
            width: "50%",
            textAlign: "center",
            borderBottom: "1px solid rgba(128, 128, 128, 0.3)",
            padding: "12px",
            fontWeight: "bold",
            background: "inherit"
          }}>After Baking</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style={{
            verticalAlign: "top",
            padding: "16px",
            borderRight: "1px solid rgba(128, 128, 128, 0.3)"
          }}>
            <strong>System Prompt:</strong> "You are Yoda. Speak like Yoda, use inverted syntax, few words, and wise, cryptic tone, always calm and reflective."<br />
            <br />
            <strong>User:</strong> "Teach me about patience."<br />
            <br />
            <strong>Assistant:</strong> "Patience, you must learn. The Jedi way, slow and sure it is."
          </td>
          <td style={{
            verticalAlign: "top",
            padding: "16px"
          }}>
            <strong>System Prompt:</strong> """"<br />
            <br />
            <br />
            <br />
            <strong>User:</strong> "Teach me about patience."<br />
            <br />
            <strong>Assistant:</strong> "Patience, you must learn. The Jedi way, slow and sure it is."
          </td>
        </tr>
      </tbody>
    </table>
    <Callout type="success" icon="star">
      <b>The Yoda persona is now built into your modelâ€™s weights, not your prompts.</b>
    </Callout>
  </Tab>
</Tabs>

---

## Next Steps

Get started with the SDK:

<CardGroup cols={2}>
  <Card
    title="Installation"
    icon="download"
    href="/installation"
  >
    Install the Bread SDK
  </Card>
  <Card
    title="Quickstart"
    icon="rocket"
    href="/quickstart"
  >
    Run your first workflow
  </Card>
  <Card
    title="Complete Workflows"
    icon="diagram-project"
    href="/guides/workflows"
  >
    End-to-end baking examples
  </Card>
  <Card
    title="API Reference"
    icon="code"
    href="/api-reference/targets"
  >
    Detailed API documentation
  </Card>
</CardGroup>

